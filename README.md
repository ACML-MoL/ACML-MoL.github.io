## Motivation and Objectives 

Multi-output learning aims to predict multiple outputs for an input, where the output values are characterized by diverse data types, such as binary, nominal, ordinal and real-valued variables. Such learning tasks arise in a variety of real-world applications, ranging from document classification, computer emulation, sensor network analysis, concept-based information retrieval, human action/causal induction, to video analysis, image annotation/retrieval, gene function prediction and brain science. Due to its popularity in applications, multi-output learning has also been widely explored in machine learning community, such as multi-label/multi-class classification, multi-target regression, hierarchical classification with class taxonomies, label sequence learning, sequence alignment learning, and supervised grammar learning, and so on. 

The theoretical properties of existing approaches for multi-output data are still not well understood. This triggers practitioners to develop novel methodologies and theories to deeply understand multi-output learning tasks. Moreover, the emerging trends of ultrahigh input and output dimensionality, and the complexly structured objects, lead to formidable challenges for multi-output learning. Therefore, it is imperative to propose practical mechanisms and efficient optimization algorithms for large-scale applications. Deep learning has gained much popularity in today’s research, and has been developed in recent years to deal with multi-label and multi-class classification problems. However, it remains non-trivial for practitioners to design novel deep neural networks that are appropriate for more comprehensive multi-output learning domains. 

## Topics of Interest 

Interested topics include, but are not limited to: 

Novel deep learning methods for multi-output learning tasks. 

Novel modellings for multi-output learning from new perspectives. 

Statistical theory analysis for multiple output learning. 

Large-scale optimization algorithms for multiple output learning. 

Sparse representation learning for large-scale multiple output learning. 

Active learning for multi-output data. 

Online learning for multi-output data. 

Metric learning for multi-output data. 

Multi-output learning with noisy data. 

Multi-output learning with imbalanced data. 

## Submission Guidelines 

We request 2-page extended abstracts with free-style to be submitted by 20th Aug, 2018. Accepted abstracts will be presented as posters. Works that had previously been published elsewhere can also be submitted as there will be no proceeding publication.  Papers should be submitted directly to the following e-mail: ACML2018ws@gmail.com

## Tentative Schedule

8:50 - 9:00 Introduction 

9:00 - 10:00 Invited Keynote Talk 

===10:00-10:30 Morning tea=== 

10:30 - 10:55 Paper presentation 

10:55 - 11:20 Paper presentation 

11:20 - 11:35 Paper presentation 

===11:35 - 11:50 Panel discussion=== 

11:50 - 12:05 Paper presentation 

12:05 - 12:20 Paper presentation 

12:20 - 12:35 Paper presentation 

===12:35 - 12:50 Panel discussion=== 


## Important Dates 

Submission: 20 Aug, 2018. 

Notification: 01 Oct, 2018. 

Workshop: 14 Nov, 2018. 

## Organizers

Weiwei Liu, University of New South Wales, Australia. 

Xiaobo Shen, Nanyang Technological University, Singapore. 

Yew-Soon Ong, Nanyang Technological University, Singapore. 

Ivor W. Tsang, University of Technology Sydney, Australia. 

Chen Gong, Nanjing University of Science and Technology, China.
